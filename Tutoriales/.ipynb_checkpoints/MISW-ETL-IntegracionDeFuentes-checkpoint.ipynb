{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Integración de fuentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "    ¿Qué aprenderá?\n",
    "        En  este tutorial  aprenderá la  importancia  de  integrar  fuentes de datos,  además  de distintas estrategias de integración y problemas comunes que surgen al intentar hacerlo.\n",
    "\n",
    "    ¿Para qué?\n",
    "        En proyectos de analítica es común tener que buscar e integrar fuentes de datos externas para cumplir con los objetivos analíticos y enriquecer los análisis. \n",
    "     \n",
    "     ¿Qué necesita?\n",
    "        1. Python 3 con pip instalado\n",
    "        2. Jupyter notebook\n",
    "        3. Paquetes: Pyspark (3.0.1)\n",
    "        4. Controlador MariaDB JDBC 2.5.3\n",
    "        5. Archivos CSV \"Customers.csv\" y \"CustomersTransactions.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Búsqueda de nuevas fuentes de datos\n",
    "\n",
    "El proceso de integración y búsqueda de fuentes está intrínsecamente ligado con el correcto entendimiento de los procesos de negocio relacionados, pues no solo es necesario entender el negocio para proponer análisis útiles que puedan beneficiarse de fuentes externas, sino que también es por medio del correcto entendimiento de los procesos de negocios, las partes y los actores relacionados al mismo, que podrá identificar posibles entidades u organizaciones que pueden tener información útil. De acuerdo con esto, hay varios lugares dentro de los cuales se puede realizar una búsqueda de fuentes, estos incluyen:\n",
    "\n",
    "<ol>\n",
    "<li>\n",
    "<b>Portales gubernamentales de datos abiertos:</b> Muchos gobiernos, tanto nacionales como departamentales o estatales, ponen a disposición del  público datos de interés general, como es el caso del gobierno de los Estados Unidos con su página https://www.data.gov/ o del gobierno colombiano con https://datos.gov.co/\n",
    "</li>\n",
    "<li>\n",
    "<b>Datos de indicadores poblacionales o económicos:</b> Es posible encontrar datos de indicadores poblacionales o económicos en varios países   generados por sus departamentos estadísticos. En Colombia, por ejemplo, el DANE(https://www.dane.gov.co/) publica datos de censos e indicadores económicos.\n",
    "</li>\n",
    "<li>\n",
    "<b>Datos de  entes  reguladores:</b> De acuerdo con el país y la regulación que aplique al proyecto, es posible que exista un ente regulador relacionado con el sector económico en el que se desempeña la organización y que, en muchos casos, tiene información pública del  sector. En Colombia,  por  ejemplo, la Aerocivil regula la aviación civil  y,  por  lo  tanto, publica información sobre vuelos, destinos, entre otros: http://www.aerocivil.gov.co/atencion/estadisticas-de-las-actividades-aeronauticas/bases-de-datos.\n",
    "</li>\n",
    "<li>\n",
    "<b>Datos   en   otras   dependencias   de   la   empresa: </b>Las formas como las distintas organizaciones administran su información varían drásticamente. Sin embargo, no es poco común encontrarse con organizaciones donde la información se encuentra compartimentada según líneas burocráticas o dependencias internas. Por lo tanto, vale la pena explorar qué datos, en posesión de distintas dependencias, podrían ser útiles para el proyecto.\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estrategias  para  la  integración  de  fuentes  de datos\n",
    "\n",
    "Una vez determinadas y conseguidas las fuentes de datos que podrían ser de utilidad para el proyecto, es importante ser capaz de integrarlas y, de este modo, poder enriquecer los análisis. La integración de fuentes, sin embargo, no siempre es tan sencilla, pues no es poco común contar con  información redundante, llaves  primarias  en  distintos  formatos,  entre otros. Deben, entonces, identificarse posibles causas de inconsistencias  y, asimismo, tomar acciones para solucionarlas y mitigarlas.\n",
    "\n",
    "Antes de intentar realizar el cruce de  las  fuentes, es importante explorar los campos que se quieren utilizar para esta integración y determinar si es necesario realizar algún proceso previo de estandarización y corrección. Por lo tanto, se recomienda seguir los siguientes pasos:\n",
    "<ol>\n",
    "<li>\n",
    "Revise que los valores faltantes tengan el mismo formato. Si es  necesario, estandarice los valores para que los faltantes sean iguales en todas  las fuentes. Por ejemplo, en alguna fuente podrían tener valores nulos, cadenas con el valor “NULL”, valores como cero, entre otros. \n",
    "</li>\n",
    "<li>\n",
    "Revise si tiene campos que podrían tener diferentes formatos en las dos fuentes y, si este es el caso, estandarícelos. <br>\n",
    "Algunos ejemplos: \n",
    "    <ul>\n",
    "    <li>\n",
    "    Fechas  en  distintos  formatos, por  ejemplo,  encontrarse  fechas  en  formato <i>año-mes-día</i> en una fuente y </i>día/mes/año</i> en otra\n",
    "    </li>\n",
    "    <li>\n",
    "    Números telefónicos o de documentos: según el país, los números telefónicos o números de documentos podrían tener puntos, guiones, espacios u otros separadores entre ellos. En Colombia, por ejemplo, es común que algunas fuentes escriban los números de cédulas de ciudadanía con puntos denotando los miles, por ejemplo 1.234.567.890.\n",
    "    </li>\n",
    "    <li>\n",
    "    Si está lidiando con campos de texto, debe tener especial cuidado, pues las variaciones que se pueden presentar son múltiples. Revise la forma como los campos manejan las mayúsculas, las tildes y acentos, los espacios, los caracteres especiales y la puntuación. Podría también ser necesario utilizar métricas, como la distancia de Hamming, para determinar similitud entre dos cadenas de caracteres.\n",
    "    </li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li>\n",
    "Revise si existe  algún estándar  dado  por  terceros para  sus campos y,  si  es  el  caso, adóptelos. Comúnmente encontrará estos estándares dados por entes gubernamentales, entes reguladores y similares. Es importante tener una adecuada comprensión de los procesos de negocio involucrados en el proyecto para, así, poder identificar estos entes. Por ejemplo, para las direcciones en Colombia existe un estándar establecido por el Departamento Administrativo de Catastro Distrital. De manera semejante, existe, para los municipios del país, el código de identificación Divipola.\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "Una vez realizada la estandarización y corrección de los datos, puede realizar la integración de las fuentes. Una vez integradas, debe revisar el resultado y, si lo determina necesario, repetir el proceso de corrección y estandarización con los nuevos problemas identificados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ejemplo\n",
    "\n",
    "Suponga que tiene dos tablas, <i>Customers</i> y <i>CustomerTransactions</i>, que quiere integrar. El código que se muestra a continuación ilustra el proceso requerido para la integración, el cual inicia con la carga de estas tablas a partir de los archivos \".csv\". Estos archivos ya están cargados en ./data. Puedes verificar su existencia, haciendo clic en el logo de Jupyter ubicado en la esquina superior izquierda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql import functions as f\n",
    "import os \n",
    "path_jar_driver = 'C:\\Program Files (x86)\\MySQL\\Connector J 8.0\\mysql-connector-java-8.0.28.jar'\n",
    "\n",
    "#Configuración de la sesión\n",
    "conf=SparkConf() \\\n",
    "    .set('spark.driver.extraClassPath', path_jar_driver)\n",
    "\n",
    "spark_context = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(spark_context)\n",
    "spark = sql_context.sparkSession\n",
    "\n",
    "df_customers = spark.read.options(header='True', inferSchema='True', delimiter=',').format('csv').load('./data/Customers.csv')\n",
    "df_customer_transactions = spark.read.options(header='True', inferSchema='True', delimiter=',').format('csv').load('./data/CustomerTransactions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Campos de ID diferentes\n",
    "Como podrá observar por las columnas, ambas tablas tienen el campo <i>CustomerID</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Columnas Customers:['CustomerID', 'CustomerName', 'BillToCustomerID', \"\n",
      " \"'CustomerCategoryID', 'BuyingGroupID', 'PrimaryContactPersonID', \"\n",
      " \"'AlternateContactPersonID', 'DeliveryMethodID', 'DeliveryCityID', \"\n",
      " \"'PostalCityID', 'CreditLimit', 'AccountOpenedDate', \"\n",
      " \"'StandardDiscountPercentage', 'IsStatementSent', 'IsOnCreditHold', \"\n",
      " \"'PaymentDays', 'PhoneNumber', 'FaxNumber', 'DeliveryRun', 'RunPosition', \"\n",
      " \"'WebsiteURL', 'DeliveryAddressLine1', 'DeliveryAddressLine2', \"\n",
      " \"'DeliveryPostalCode', 'DeliveryLocation', 'PostalAddressLine1', \"\n",
      " \"'PostalAddressLine2', 'PostalPostalCode', 'LastEditedBy', 'ValidFrom', \"\n",
      " \"'ValidTo']\")\n",
      "------------------------------------------------------------------------\n",
      "(\"Columnas CustomerTransaction:['CustomerTransactionID', 'CustomerID', \"\n",
      " \"'TransactionTypeID', 'InvoiceID', 'PaymentMethodID', 'TransactionDate', \"\n",
      " \"'AmountExcludingTax', 'TaxAmount', 'TransactionAmount', \"\n",
      " \"'OutstandingBalance', 'IsFinalized']\")\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(\"Columnas Customers:\" + str(df_customers.columns))\n",
    "print('------------------------------------------------------------------------')\n",
    "pprint(\"Columnas CustomerTransaction:\" + str(df_customer_transactions.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, si explora este campo en cada una de las tablas, notará que, en realidad, manejan formatos diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerId en Customers:\n",
      "+----------+\n",
      "|CustomerID|\n",
      "+----------+\n",
      "|         1|\n",
      "|         2|\n",
      "|         3|\n",
      "|         4|\n",
      "|         5|\n",
      "|         6|\n",
      "|         7|\n",
      "|         8|\n",
      "|         9|\n",
      "|        10|\n",
      "|        11|\n",
      "|        12|\n",
      "|        13|\n",
      "|        14|\n",
      "|        15|\n",
      "|        16|\n",
      "|        17|\n",
      "|        18|\n",
      "|        19|\n",
      "|        20|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CustomerId en CustomerTransactions:\n",
      "+----------+\n",
      "|CustomerID|\n",
      "+----------+\n",
      "|     832-3|\n",
      "|     803-1|\n",
      "|     6-Jan|\n",
      "|     4-Jan|\n",
      "|    905-10|\n",
      "|     976-2|\n",
      "|     401-5|\n",
      "|     964-7|\n",
      "|    10-Jan|\n",
      "|    10-Jan|\n",
      "|     401-7|\n",
      "|     401-5|\n",
      "|     401-1|\n",
      "|     870-1|\n",
      "|     991-4|\n",
      "|     401-1|\n",
      "|     910-9|\n",
      "|     949-4|\n",
      "|    973-10|\n",
      "|     884-3|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CustomerId en Customers:\")\n",
    "df_customers.select('CustomerID').show()\n",
    "print(\"CustomerId en CustomerTransactions:\")\n",
    "df_customer_transactions.select('CustomerID').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede observar, en la tabla <i>Customer Transactions</i>, los ids parecen tener algún tipo de dígito de verificación al final, denotado por el guión. Aunque este es un ejemplo simple, encontrar inconsistencias en fuentes que guardan el dígito de verificación de un id y fuentes que no lo hacen, es muy común en el caso de los números de identicación tributaria (NIT) en Colombia.\n",
    "\n",
    "Se debe, entonces, quitar el número de verificación, esto se realizará utilizando la función <i>split</i>, que permite dividir una cadena de caracteres. Adicionalmente, se convertirá el tipo de la columna resultante a entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_transactions = df_customer_transactions.withColumn('CustomerID', f.split(df_customer_transactions['CustomerID'], '-').getItem(0).cast('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, los identificadores se encuentran corregidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerId en CustomerTransactions:\n",
      "+----------+\n",
      "|CustomerID|\n",
      "+----------+\n",
      "|       832|\n",
      "|       803|\n",
      "|         6|\n",
      "|         4|\n",
      "|       905|\n",
      "|       976|\n",
      "|       401|\n",
      "|       964|\n",
      "|        10|\n",
      "|        10|\n",
      "|       401|\n",
      "|       401|\n",
      "|       401|\n",
      "|       870|\n",
      "|       991|\n",
      "|       401|\n",
      "|       910|\n",
      "|       949|\n",
      "|       973|\n",
      "|       884|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CustomerId en CustomerTransactions:\")\n",
    "df_customer_transactions.select('CustomerID').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Fechas con distintos formatos\n",
    "\n",
    "Si explora más los datos a integrar, observará que las dos tablas manejan formatos de fechas diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fechas en Customers:\n",
      "+--------------------+\n",
      "|           ValidFrom|\n",
      "+--------------------+\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "|2013-01-01 00:00:...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Fechas en CustomerTransactions:\n",
      "+---------------+\n",
      "|TransactionDate|\n",
      "+---------------+\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "|       1/1/2013|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fechas en Customers:\")\n",
    "df_customers.select('ValidFrom').show()\n",
    "print(\"Fechas en CustomerTransactions:\")\n",
    "df_customer_transactions.select('TransactionDate').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras que <i>Customers</i> maneja un formato <i>yyyy-MM-dd HH:mm:ss</i>, <i>Customer Transactions</i> tiene sus fechas en formato <i>d/M/yyyy</i>. Se debe, entonces, ajustar el formato de fechas de <i>CustomerTransactions</i>, para esto se utiliza la función <i>to_timestamp</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------+-----------------+---------+---------------+-------------------+------------------+---------+-----------------+------------------+-----------+\n",
      "|CustomerTransactionID|CustomerID|TransactionTypeID|InvoiceID|PaymentMethodID|    TransactionDate|AmountExcludingTax|TaxAmount|TransactionAmount|OutstandingBalance|IsFinalized|\n",
      "+---------------------+----------+-----------------+---------+---------------+-------------------+------------------+---------+-----------------+------------------+-----------+\n",
      "|                    2|       832|                1|        1|            N/A|2013-01-01 00:00:00|            2300.0|    345.0|           2645.0|               0.0|          1|\n",
      "|                    5|       803|                1|        2|            N/A|2013-01-01 00:00:00|             405.0|    60.75|           465.75|               0.0|          1|\n",
      "|                    7|         6|                1|        3|            N/A|2013-01-01 00:00:00|              90.0|     13.5|            103.5|               0.0|          1|\n",
      "|                   11|         4|                1|        4|            N/A|2013-01-01 00:00:00|             445.2|    66.78|           511.98|               0.0|          1|\n",
      "|                   15|       905|                1|        5|            N/A|2013-01-01 00:00:00|             704.0|    105.6|            809.6|               0.0|          1|\n",
      "|                   19|       976|                1|        6|            N/A|2013-01-01 00:00:00|             430.0|     64.5|            494.5|               0.0|          1|\n",
      "|                   24|       401|                1|        7|            N/A|2013-01-01 00:00:00|             603.5|    90.53|           694.03|               0.0|          1|\n",
      "|                   28|       964|                1|        8|            N/A|2013-01-01 00:00:00|             258.0|     38.7|            296.7|               0.0|          1|\n",
      "|                   31|        10|                1|        9|            N/A|2013-01-01 00:00:00|             178.0|     26.7|            204.7|               0.0|          1|\n",
      "|                   34|        10|                1|       10|            N/A|2013-01-01 00:00:00|             104.0|     15.6|            119.6|               0.0|          1|\n",
      "|                   36|       401|                1|       11|            N/A|2013-01-01 00:00:00|              13.0|     1.95|            14.95|               0.0|          1|\n",
      "|                   39|       401|                1|       12|            N/A|2013-01-01 00:00:00|             229.0|    34.35|           263.35|               0.0|          1|\n",
      "|                   42|       401|                1|       13|            N/A|2013-01-01 00:00:00|            2430.0|    364.5|           2794.5|               0.0|          1|\n",
      "|                   46|       870|                1|       14|            N/A|2013-01-01 00:00:00|             650.0|     97.5|            747.5|               0.0|          1|\n",
      "|                   49|       991|                1|       15|            N/A|2013-01-01 00:00:00|             174.0|     26.1|            200.1|               0.0|          1|\n",
      "|                   51|       401|                1|       16|            N/A|2013-01-01 00:00:00|              68.0|     10.2|             78.2|               0.0|          1|\n",
      "|                   54|       910|                1|       17|            N/A|2013-01-01 00:00:00|             424.0|     63.6|            487.6|               0.0|          1|\n",
      "|                   56|       949|                1|       18|            N/A|2013-01-01 00:00:00|              91.0|    13.65|           104.65|               0.0|          1|\n",
      "|                   60|       973|                1|       19|            N/A|2013-01-01 00:00:00|            3185.0|   477.75|          3662.75|               0.0|          1|\n",
      "|                   62|       884|                1|       20|            N/A|2013-01-01 00:00:00|             240.0|     36.0|            276.0|               0.0|          1|\n",
      "+---------------------+----------+-----------------+---------+---------------+-------------------+------------------+---------+-----------------+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customer_transactions = df_customer_transactions.withColumn('TransactionDate', f.to_timestamp(df_customer_transactions['TransactionDate'], \"d/M/yyyy\"))\n",
    "\n",
    "df_customer_transactions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ejercicio\n",
    "\n",
    "Como puede ver en los datos de <i>CustomerTransactions</i>, la columna <i>PaymentMethodID</i>  contiene cadenas de caracteres \"N/A\" en lugar de valores nulos. Convierta los \"N/A\" a nulos, remueva los valores nulos e integre esta fuente con Customers. El DataFrame final deberá tener 17660331 registros en total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cierre \n",
    "Completado este tutorial, ya tiene una noción de cómo buscar fuentes de datos extra para enriquecer sus análisis, a qué tipos de problemas podría enfrentarse al hacer la integración y algunas estrategias que puede usar para realizarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
